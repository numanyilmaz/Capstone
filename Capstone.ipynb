{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.3 |Anaconda custom (64-bit)| (default, Oct  6 2017, 12:04:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Numpy version 1.14.0\n",
      "Pandas version 0.20.3\n",
      "Matplotlib version 2.1.2\n",
      "Seaborn version 0.8.0\n",
      "Sklearn version: 0.19.1\n",
      "Missingno version: 0.3.5\n",
      "Xgboost version: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and check the versions\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "print('Python version: {}'.format(sys.version))\n",
    "print('Numpy version {}'.format(np.__version__))\n",
    "print('Pandas version {}'.format(pd.__version__))\n",
    "print('Matplotlib version {}'.format(mpl.__version__))\n",
    "print('Seaborn version {}'.format(sns.__version__))\n",
    "print('Sklearn version: {}'.format(sklearn.__version__))\n",
    "print('Missingno version: {}'.format(msno.__version__))\n",
    "print(\"Xgboost version: {}\".format(xgb.__version__))\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# for more clear plots\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset can be found at kaggle's website. First column of the dataset is the index column and we specify that with index_col = 0. Let's see the first five records of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the data\n",
    "df = pd.read_csv('h1b_kaggle.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do explonatary data analysis, we need to select necessary features and clean the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features that will be used creating the model\n",
    "data = df[['CASE_STATUS', 'SOC_NAME',\n",
    "       'FULL_TIME_POSITION', 'PREVAILING_WAGE', 'WORKSITE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missigno is a library that allows us to visualize missing data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "msno.matrix(data.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missing data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the missing values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all strings to uppercase \n",
    "data['SOC_NAME'] = data['SOC_NAME'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove everthing after comma from job title\n",
    "data['SOC_NAME'] = data['SOC_NAME'].apply(lambda x: x.split(', ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There \n",
    "data[data['SOC_NAME'].str.contains('CARPI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['SOC_NAME'].str.contains('CARPI')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current format of the worksite column is **City Name, State**, for this study we will focus on only state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove city names from worksite column\n",
    "data['WORKSITE'] = data['WORKSITE'].apply(lambda x: x.split(', ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "data['PREVAILING_WAGE'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there are outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['PREVAILING_WAGE'] > 500000) | (data['PREVAILING_WAGE'] < 25000)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Approxiametly, 12000 wages are below 25000 or above 500000 dollars, those records will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data[(data['PREVAILING_WAGE'] < 500000)]\n",
    "cleaned_data = cleaned_data[(cleaned_data['PREVAILING_WAGE'] > 25000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CASE_STATUS** : This is our target feature. There were 7 possible values in the dataset and we reduced it to 2. Because only one status has a positive result and rest of the statues have a negative result. \n",
    "\n",
    "**SOC_NAME** : Type of the job. There are 1584 unique jobs in the dataset.\n",
    "\n",
    "**FULL_TIME_POSITION** : This column indicates if the job is full time or not. \n",
    "\n",
    "**WORKSITE** : Location of the job. Original column had the state and city information. I removed the cities. The model is going to make predictions based on the state information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of columns\n",
    "cleaned_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Number of records: ', cleaned_data.shape[0])\n",
    "print ('Number of positive cases: ', cleaned_data['CASE_STATUS'].value_counts()[0])\n",
    "print ('Number of negative cases: ', cleaned_data['CASE_STATUS'].value_counts()[1])\n",
    "print ('Percentage of positive cases: ', \\\n",
    "       cleaned_data['CASE_STATUS'].value_counts()[0] * 100 / cleaned_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the null values, we still have close to 3 million records. There are 4 features which are SOC_NAME, FULL_TIME_POSITION, PREVAILING_WAGE and WORKSITE. Our target value is CASE_STATUS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['CASE_STATUS'].value_counts().plot(kind='bar', alpha=0.5)\n",
    "plt.title('Distribution of case statuses')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('Distribution_of_case_status.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more positive case results than negative results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique values in each column\n",
    "for column in cleaned_data:\n",
    "    print(column, cleaned_data[column].nunique())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['WORKSITE'].groupby(cleaned_data['WORKSITE']).count()\\\n",
    "                .sort_values(ascending=False).head(10).plot(kind='bar', alpha=0.5)\n",
    "plt.title('Top 10 cities for H1-B visa')\n",
    "plt.savefig('Top_cities.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['FULL_TIME_POSITION'].value_counts().plot(kind='bar', alpha=0.5)\n",
    "plt.title('Distribution of Full Time - Part Time')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.groupby(['CASE_STATUS','FULL_TIME_POSITION']).count()['SOC_NAME'].\\\n",
    "            unstack().plot(kind='barh',figsize=(12,5), alpha=0.5)\n",
    "plt.title('Case Status versus Type of position')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'PREVAILING_WAGE'\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(211)\n",
    "plt.xlim(cleaned_data[i].min(), cleaned_data[i].max()*1.1)\n",
    "\n",
    "ax = cleaned_data[i].plot(kind='kde')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.xlim(cleaned_data[i].min(), cleaned_data[i].max()*1.1)\n",
    "sns.boxplot(x=cleaned_data[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have two plots, the density plot and the box plot. This is a good way to view the data as we can see in the density plot (top) that there is some data points in the tails but it is difficult to see, however it is clear in the box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For highly sckewed features, it is always good to do transformation. **PREVAILING_WAGE** column has tail on the right and we will apply logarithmic transformation on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform the data\n",
    "cleaned_data['Log_' + i] = np.log(cleaned_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'Log_PREVAILING_WAGE'\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(211)\n",
    "plt.xlim(cleaned_data[i].min(), cleaned_data[i].max()*1.1)\n",
    "\n",
    "ax = cleaned_data[i].plot(kind='kde')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.xlim(cleaned_data[i].min(), cleaned_data[i].max()*1.1)\n",
    "sns.boxplot(x=cleaned_data[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time to scale transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['Log_PREVAILING_WAGE']\n",
    "\n",
    "transformed_data = pd.DataFrame(data = cleaned_data)\n",
    "transformed_data[numerical] = scaler.fit_transform(cleaned_data[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove original wage column \n",
    "del transformed_data['PREVAILING_WAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "transformed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['CASE_STATUS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are seven types of case statues but only the \"CERTIFIED\" have a positive result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['CASE_STATUS'] = transformed_data['CASE_STATUS'].apply(lambda x: 1 if x == 'CERTIFIED' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the transformed data using pandas.get_dummies()\n",
    "features_final = pd.get_dummies(transformed_data, columns=['SOC_NAME', 'FULL_TIME_POSITION', 'WORKSITE'])\n",
    "\n",
    "# \n",
    "transformed_data['FULL_TIME_POSITION'] = transformed_data['FULL_TIME_POSITION'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print (\"total features after one-hot encoding: \", len(encoded))\n",
    "\n",
    "# Uncomment the following line to see the encoded feature names\n",
    "#print encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of final features: \", (features_final.shape))\n",
    "\n",
    "#first 5 rows\n",
    "features_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = features_final[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_final.iloc[:,1:]\n",
    "y = features_final['CASE_STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training set has samples: \", (X_train.shape[0]))\n",
    "print (\"Testing set has samples: \",  (X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_1 = LogisticRegression(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_2 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf_3 = XGBClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#make predictions for test data\n",
    "y_pred = clf_1.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions for test data\n",
    "y_pred = clf_2.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make predictions for test data\n",
    "y_pred = clf_3.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate accuracy, precision and recall\n",
    "TP = np.sum(y)\n",
    "TN = 0\n",
    "FP = y.count() - np.sum(y)\n",
    "FN = 0\n",
    "\n",
    "accuracy = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "# TODO: Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
    "# HINT: The formula above can be written as (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "beta = 0.5\n",
    "fscore = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "\n",
    "# Print the results \n",
    "print (\"Naive Predictor: [Accuracy score: \", accuracy, \"F-score:\" ,fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
